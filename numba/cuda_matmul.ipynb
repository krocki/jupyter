{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd149718-a9e1-48e9-ac77-667f380cfd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu time = 0.0007545948028564453 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krocki/.local/lib/python3.8/site-packages/numba/cuda/compiler.py:865: NumbaPerformanceWarning: \u001b[1mGrid size (64) < 2 * SM count (216) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu time = 0.32591843605041504 s\n",
      "cpu=array([[-12.32922   ,  10.799813  ,  -1.9149985 , ...,   4.6531787 ,\n",
      "          6.22411   ,  -0.3889591 ],\n",
      "       [ -1.4291192 ,   0.7369752 ,   2.2361498 , ...,   3.9228063 ,\n",
      "         -2.4182982 ,   7.3295965 ],\n",
      "       [ -2.942463  , -14.044039  ,  -3.5106852 , ...,  -5.270478  ,\n",
      "          6.2338905 ,   0.46176562],\n",
      "       ...,\n",
      "       [  4.2029166 ,  -6.642787  ,   4.9657907 , ...,   1.5351754 ,\n",
      "          1.206077  ,  -4.886201  ],\n",
      "       [  2.1515427 ,  -6.754644  ,   2.4469705 , ...,  -4.249156  ,\n",
      "          0.03139742,  -5.661947  ],\n",
      "       [ -0.72065705,   0.24282883,  -1.875034  , ...,  -8.139893  ,\n",
      "          0.6097091 ,  -8.083664  ]], dtype=float32)\n",
      "c=array([[-12.329219  ,  10.799812  ,  -1.9149987 , ...,   4.653178  ,\n",
      "          6.2241096 ,  -0.38895994],\n",
      "       [ -1.429119  ,   0.7369754 ,   2.2361493 , ...,   3.922806  ,\n",
      "         -2.4182968 ,   7.3295975 ],\n",
      "       [ -2.942463  , -14.044038  ,  -3.5106854 , ...,  -5.270478  ,\n",
      "          6.233892  ,   0.46176547],\n",
      "       ...,\n",
      "       [  4.202916  ,  -6.642787  ,   4.96579   , ...,   1.5351757 ,\n",
      "          1.2060766 ,  -4.886201  ],\n",
      "       [  2.1515427 ,  -6.754644  ,   2.4469702 , ...,  -4.249156  ,\n",
      "          0.03139728,  -5.6619463 ],\n",
      "       [ -0.72065705,   0.2428287 ,  -1.8750345 , ...,  -8.139894  ,\n",
      "          0.6097091 ,  -8.083665  ]], dtype=float32)\n",
      "err=0.00015766082\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, types, float32\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_HOME\"]=\"/usr/local/cuda\"\n",
    "\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp\n",
    "        \n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    TPB = N\n",
    "\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp\n",
    "\n",
    "# This part is for initializing everything\n",
    "M = 256\n",
    "N = 32\n",
    "\n",
    "#a = np.arange(M*N).reshape(M,N).astype(np.float32)\n",
    "#b = np.arange(M*N).reshape(N,M).astype(np.float32)\n",
    "a = np.random.randn(M, N).astype(np.float32)\n",
    "b = np.random.randn(N, M).astype(np.float32)\n",
    "c = np.zeros((M, M)).astype(np.float32)\n",
    "\n",
    "t0 = time()\n",
    "cpu = np.dot(a, b)\n",
    "print(f'cpu time = {time()-t0} s')\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.to_device(c)\n",
    "\n",
    "block_size = (N,N)\n",
    "grid_size = (int(M/N),int(M/N))\n",
    "\n",
    "t0 = time()\n",
    "matmul[grid_size,block_size](d_a, d_b, d_c)\n",
    "#fast_matmul[grid_size,block_size](d_a, d_b, d_c)\n",
    "print(f'gpu time = {time()-t0} s')\n",
    "\n",
    "c = d_c.copy_to_host()\n",
    "print(f'{cpu=}')\n",
    "print(f'{c=}')\n",
    "err = np.linalg.norm(cpu - c)\n",
    "print(f'{err=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbba317-173a-422d-9bc5-f9624854ab1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
